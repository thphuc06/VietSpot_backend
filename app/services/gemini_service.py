import os
import tempfile
from google import genai
from google.genai.types import (
    GenerateContentConfig,
    GoogleSearch,
    HttpOptions,
    Tool,
)
from app.core.config import settings
from app.schemas.chat import QueryClassification
import json
import re


class GeminiService:
    def __init__(self):
        # Setup Google Cloud credentials from environment variable (for Railway/Cloud deployment)
        self._setup_credentials()
        
        # Setup Vertex AI
        os.environ["GOOGLE_CLOUD_PROJECT"] = settings.VERTEX_PROJECT_ID
        os.environ["GOOGLE_CLOUD_LOCATION"] = settings.VERTEX_LOCATION
        os.environ["GOOGLE_GENAI_USE_VERTEXAI"] = "True"
        
        # Create Vertex AI client
        self.client = genai.Client(http_options=HttpOptions(api_version="v1"))
        self.model_id = settings.VERTEX_MODEL_ID
        
        # Tools for grounding
        self.grounding_tools = [Tool(google_search=GoogleSearch())]
    
    def _setup_credentials(self):
        """Setup Google Cloud credentials from environment variable"""
        # Check if credentials JSON is provided as environment variable
        credentials_json = os.environ.get("GOOGLE_CREDENTIALS_JSON")
        
        if credentials_json:
            # Write credentials to a temporary file
            try:
                # Create a temporary file for credentials
                fd, path = tempfile.mkstemp(suffix='.json')
                with os.fdopen(fd, 'w') as f:
                    f.write(credentials_json)
                
                # Set the path for Google libraries to find
                os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = path
                print(f"‚úÖ Loaded Google credentials from environment variable")
            except Exception as e:
                print(f"‚ö†Ô∏è Error setting up credentials: {e}")
        else:
            # Check if already set via file path
            if os.environ.get("GOOGLE_APPLICATION_CREDENTIALS"):
                print(f"‚úÖ Using existing GOOGLE_APPLICATION_CREDENTIALS")
            else:
                print(f"‚ö†Ô∏è No Google credentials found. Vertex AI may not work.")
    
    def _clean_text(self, text: str) -> str:
        """Remove control characters and clean text"""
        if not text:
            return ''
        # Remove control characters except space, tab (keep tab for formatting)
        text = ''.join(char if ord(char) >= 32 or char in ['\t'] else ' ' for char in text)
        # Replace multiple spaces with single space
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    
    def _clean_json_string(self, json_str: str) -> str:
        """Clean JSON string - just strip whitespace, json.loads() handles escapes"""
        if not json_str:
            return json_str
        return json_str.strip()
        
    def classify_query(self, user_prompt: str) -> QueryClassification:
        """
        Classify user query and extract relevant information
        Returns query type: general_query, nearby_search, or specific_search
        """
        
        classification_prompt = f"""
Ph√¢n t√≠ch c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng v√† tr·∫£ v·ªÅ th√¥ng tin d∆∞·ªõi d·∫°ng JSON v·ªõi c·∫•u tr√∫c sau:

{{
    "query_type": "general_query" ho·∫∑c "nearby_search" ho·∫∑c "specific_search",
    "keywords": ["t·ª´ kh√≥a 1", "t·ª´ kh√≥a 2", ...],
    "location_mentioned": "t√™n ƒë·ªãa ƒëi·ªÉm chu·∫©n h√≥a (ƒë√£ s·ª≠a l·ªói ch√≠nh t·∫£) n·∫øu c√≥, null n·∫øu kh√¥ng",
    "city": "t√™n th√†nh ph·ªë/t·ªânh ƒë√£ chu·∫©n h√≥a (v√≠ d·ª•: 'H·ªì Ch√≠ Minh', 'H√† N·ªôi', 'ƒê√† N·∫µng'), null n·∫øu kh√¥ng c√≥",
    "district": "t√™n qu·∫≠n/huy·ªán/ph∆∞·ªùng ƒë√£ chu·∫©n h√≥a (v√≠ d·ª•: 'Qu·∫≠n 1', 'B√¨nh Th·∫°nh', 'Ho√†n Ki·∫øm'), null n·∫øu kh√¥ng c√≥",
    "min_rating": s·ªë rating t·ªëi thi·ªÉu (1.0-5.0) n·∫øu ng∆∞·ªùi d√πng y√™u c·∫ßu, null n·∫øu kh√¥ng,
    "max_rating": s·ªë rating t·ªëi ƒëa (1.0-5.0) n·∫øu ng∆∞·ªùi d√πng y√™u c·∫ßu, null n·∫øu kh√¥ng,
    "price_range": "cheap/moderate/expensive n·∫øu c√≥ ƒë·ªÅ c·∫≠p, null n·∫øu kh√¥ng",
    "category": "lo·∫°i h√¨nh ƒë·ªãa ƒëi·ªÉm (restaurant, cafe, hotel, tourist_attraction, etc.) n·∫øu c√≥, null n·∫øu kh√¥ng",
    "radius_km": s·ªë km n·∫øu ng∆∞·ªùi d√πng ƒë·ªÅ c·∫≠p (v√≠ d·ª•: "g·∫ßn t√¥i 2km" -> 2), null n·∫øu kh√¥ng,
    "number_of_places": s·ªë l∆∞·ª£ng ƒë·ªãa ƒëi·ªÉm n·∫øu ng∆∞·ªùi d√πng y√™u c·∫ßu, null n·∫øu kh√¥ng,
    "vietnamese_query": "c√¢u h·ªèi ƒë√£ s·ª≠a l·ªói ch√≠nh t·∫£ v√† d·ªãch sang ti·∫øng Vi·ªát chu·∫©n",
    "corrected_query": "c√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c s·ª≠a l·ªói ch√≠nh t·∫£, d√πng cho keyword search v√† embedding"
}}

Quy t·∫Øc ph√¢n lo·∫°i (QUAN TR·ªåNG - ∆∞u ti√™n theo th·ª© t·ª±):
1. "general_query": C√¢u h·ªèi chung, kh√¥ng li√™n quan ƒë·∫øn ƒë·ªãa ƒëi·ªÉm c·ª• th·ªÉ

2. "nearby_search": ∆ØU TI√äN CAO NH·∫§T - Khi c√≥ B·∫§T K·ª≤ t·ª´ n√†o sau: "g·∫ßn t√¥i", "g·∫ßn ƒë√¢y", "xung quanh", "quanh ƒë√¢y", "nearby", "around me", "trong v√≤ng", "c√°ch t√¥i"

3. "specific_search": CH·ªà khi c√≥ ƒê·ªäA ƒêI·ªÇM C·ª§ TH·ªÇ (t√™n th√†nh ph·ªë/qu·∫≠n) V√Ä KH√îNG c√≥ "g·∫ßn t√¥i"

C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: "{user_prompt}"

Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng th√™m gi·∫£i th√≠ch.
"""
        
        try:
            response = self.client.models.generate_content(
                model=self.model_id,
                contents=classification_prompt
            )
            result_text = response.text.strip()
            
            # Extract JSON from markdown code blocks if present
            json_match = re.search(r'```json\s*(.*?)\s*```', result_text, re.DOTALL)
            if json_match:
                result_text = json_match.group(1)
            else:
                json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
                if json_match:
                    result_text = json_match.group(0)
            
            classification_data = json.loads(result_text)
            return QueryClassification(**classification_data)
            
        except Exception as e:
            print(f"Error in classify_query: {e}")
            # Fallback
            return QueryClassification(
                query_type="specific_search",
                keywords=[],
                vietnamese_query=user_prompt,
                corrected_query=user_prompt
            )
    
    def answer_general_query(self, user_prompt: str) -> str:
        """
        Answer general queries with Google Search Grounding for realtime info
        """
        general_prompt = f"""
B·∫°n l√† tr·ª£ l√Ω du l·ªãch th√¥ng minh c·ªßa VietSpot. H√£y tr·∫£ l·ªùi c√¢u h·ªèi sau m·ªôt c√°ch th√¢n thi·ªán v√† h·ªØu √≠ch:

C√¢u h·ªèi: {user_prompt}

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ng·∫Øn g·ªçn v√† d·ªÖ hi·ªÉu.
"""
        try:
            print(f"üîç Using Google Search Grounding for general query...")
            response = self.client.models.generate_content(
                model=self.model_id,
                contents=general_prompt,
                config=GenerateContentConfig(
                    tools=self.grounding_tools
                )
            )
            return response.text
        except Exception as e:
            print(f"Error in answer_general_query: {e}")
            return "Xin l·ªói, t√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y l√∫c n√†y. Vui l√≤ng th·ª≠ l·∫°i."
    
    def select_places_and_generate_response(
        self, 
        user_prompt: str, 
        places: list, 
        max_places: int = 5,
        weather_data: dict = None
    ) -> tuple[list, str]:
        """
        Let Gemini select relevant places AND generate final response in ONE request
        Returns: (selected_places, answer_text)
        """
        if not places:
            return [], "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y ƒë·ªãa ƒëi·ªÉm n√†o ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n."
        
        # Prepare places information for Gemini
        places_info = []
        for idx, place in enumerate(places):
            about_text = place.get('about', '')
            if isinstance(about_text, dict):
                about_text = str(about_text)
            elif about_text is None:
                about_text = ''
            else:
                about_text = str(about_text)
            
            about_text = self._clean_text(about_text)[:200]
            
            place_info = {
                "index": idx,
                "id": place.get('id', f'place_{idx}'),
                "name": self._clean_text(str(place.get('name', 'N/A'))),
                "address": self._clean_text(str(place.get('address', 'Kh√¥ng c√≥ th√¥ng tin'))),
                "category": self._clean_text(str(place.get('category', 'Kh√¥ng r√µ'))),
                "rating": place.get('rating', 'N/A'),
                "rating_count": place.get('rating_count', 'N/A'),
                "price_level": self._clean_text(str(place.get('price_level', 'Kh√¥ng r√µ'))),
                "distance_km": place.get('distance_km', 'N/A'),
                "phone": self._clean_text(str(place.get('phone', 'N/A'))),
                "website": self._clean_text(str(place.get('website', 'N/A'))),
                "opening_hours": self._clean_text(str(place.get('opening_hours', 'N/A'))),
                "about": about_text
            }
            places_info.append(place_info)
        
        places_json = json.dumps(places_info, ensure_ascii=False, indent=2)
        
        weather_text = ""
        if weather_data:
            weather_text = f"""
Th√¥ng tin th·ªùi ti·∫øt hi·ªán t·∫°i:
- Nhi·ªát ƒë·ªô: {weather_data.get('temp', 'N/A')}¬∞C
- C·∫£m gi√°c nh∆∞: {weather_data.get('feels_like', 'N/A')}¬∞C
- M√¥ t·∫£: {weather_data.get('description', 'N/A')}
- ƒê·ªô ·∫©m: {weather_data.get('humidity', 'N/A')}%
"""
        
        combined_prompt = f"""
B·∫°n l√† tr·ª£ l√Ω du l·ªãch th√¥ng minh VietSpot. Nhi·ªám v·ª• c·ªßa b·∫°n:
1. CH·ªåN c√°c ƒë·ªãa ƒëi·ªÉm PH√ô H·ª¢P NH·∫§T t·ª´ danh s√°ch
2. T·∫†O c√¢u tr·∫£ l·ªùi t·ª± nhi√™n, th√¢n thi·ªán gi·ªõi thi·ªáu c√°c ƒë·ªãa ƒëi·ªÉm ƒë√£ ch·ªçn

C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: "{user_prompt}"

Danh s√°ch ƒë·ªãa ƒëi·ªÉm ·ª©ng vi√™n ({len(places_info)} ƒë·ªãa ƒëi·ªÉm):
{places_json}

{weather_text}

B∆Ø·ªöC 1: CH·ªåN ƒê·ªäA ƒêI·ªÇM
- Ch·ªçn T·ªêI ƒêA {max_places} ƒë·ªãa ƒëi·ªÉm ph√π h·ª£p nh·∫•t
- ∆Øu ti√™n: ƒë√°nh gi√° cao, th√¥ng tin r√µ r√†ng, g·∫ßn ng∆∞·ªùi d√πng, ph√π h·ª£p ng·ªØ c·∫£nh

B∆Ø·ªöC 2: T·∫†O C√ÇU TR·∫¢ L·ªúI
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát t·ª± nhi√™n, th√¢n thi·ªán
- S·ª≠ d·ª•ng markdown v·ªõi **bold** cho t√™n ƒë·ªãa ƒëi·ªÉm

Tr·∫£ v·ªÅ JSON v·ªõi c·∫•u tr√∫c:
{{
    "selected_indices": [0, 2, 5, ...],
    "answer": "C√¢u tr·∫£ l·ªùi chi ti·∫øt gi·ªõi thi·ªáu c√°c ƒë·ªãa ƒëi·ªÉm..."
}}

Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng th√™m gi·∫£i th√≠ch.
"""
        
        try:
            response = self.client.models.generate_content(
                model=self.model_id,
                contents=combined_prompt
            )
            result_text = response.text.strip()
            print(f"üì• Raw Gemini response (first 300 chars): {result_text[:300]}")
            
            # Try multiple JSON extraction methods
            json_text = None
            
            # Method 1: Extract from ```json ... ``` blocks
            json_match = re.search(r'```json\s*(\{[\s\S]*?\})\s*```', result_text, re.MULTILINE)
            if json_match:
                json_text = json_match.group(1)
            
            # Method 2: Extract from ``` ... ``` blocks
            if not json_text:
                json_match = re.search(r'```\s*(\{[\s\S]*?\})\s*```', result_text, re.MULTILINE)
                if json_match:
                    json_text = json_match.group(1)
            
            # Method 3: Use entire response if it looks like JSON
            if not json_text and result_text.startswith('{'):
                brace_count = 0
                for i, char in enumerate(result_text):
                    if char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            json_text = result_text[:i+1]
                            break
            
            # Method 4: Find first JSON object in text
            if not json_text:
                start = result_text.find('{')
                if start != -1:
                    brace_count = 0
                    for i in range(start, len(result_text)):
                        if result_text[i] == '{':
                            brace_count += 1
                        elif result_text[i] == '}':
                            brace_count -= 1
                            if brace_count == 0:
                                json_text = result_text[start:i+1]
                                break
            
            if not json_text:
                raise ValueError("Could not extract valid JSON from response")
            
            json_text = self._clean_json_string(json_text.strip())
            
            result_data = json.loads(json_text)
            selected_indices = result_data.get('selected_indices', [])
            answer = result_data.get('answer', '')
            
            print(f"ü§ñ Gemini selected {len(selected_indices)} places and generated response")
            
            # Return selected places
            selected_places = []
            for idx in selected_indices:
                if 0 <= idx < len(places):
                    selected_places.append(places[idx])
            
            # If no valid selection, return top places
            if not selected_places:
                print("‚ö†Ô∏è No valid selection, returning top places")
                selected_places = places[:max_places]
            
            if not answer:
                answer = "D∆∞·ªõi ƒë√¢y l√† c√°c ƒë·ªãa ƒëi·ªÉm g·ª£i √Ω cho b·∫°n."
            
            return selected_places, answer
            
        except Exception as e:
            print(f"‚ùå Error in select_places_and_generate_response: {e}")
            return places[:max_places], "D∆∞·ªõi ƒë√¢y l√† c√°c ƒë·ªãa ƒëi·ªÉm g·ª£i √Ω cho b·∫°n."
